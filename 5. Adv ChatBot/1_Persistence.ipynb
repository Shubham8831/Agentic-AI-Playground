{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "759efc54",
   "metadata": {},
   "source": [
    "# 📌 Persistence\n",
    "\n",
    "- **Definition:**\n",
    "Ability to save and restore the state of a workflow over time.\n",
    "\n",
    "Core behavior of LangGraph:\n",
    "When a workflow ends, the value of the final state is deleted.\n",
    "\n",
    "With persistence:\n",
    "\n",
    "We can save the state.\n",
    "\n",
    "Persistence also saves all the values from intermediate states (if any value is changed).\n",
    "\n",
    "\n",
    "- **Fault tolerance:**\n",
    "\n",
    "If any node fails during the workflow, the intermediate state value is saved.\n",
    "\n",
    "The workflow can be restarted from where it failed.\n",
    "\n",
    "This feature is called fault tolerance.\n",
    "\n",
    "\n",
    "- **Applications:**\n",
    "Helps in building chatbots.\n",
    "\n",
    "- **Implementation:**\n",
    "Persistence in LangGraph is implemented using checkpoints.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### 📌 Checkpoints in Persistence\n",
    "\n",
    "- **Checkpoint Diagram:**\n",
    "\n",
    "Workflow progresses through nodes and supersteps.\n",
    "\n",
    "At various points (e.g., start, nodes, end), checkpoints are taken.\n",
    "\n",
    "\n",
    "- **Supersteps:**\n",
    "\n",
    "Each superstep of the graph is treated as a checkpoint.\n",
    "\n",
    "Checkpoints save the state values for database persistence.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "- **📌 Threads in Persistence**\n",
    "\n",
    "Each time a workflow is executed, different thread IDs are assigned.\n",
    "\n",
    "Using these thread IDs, state values can be retrieved later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7680c0",
   "metadata": {},
   "source": [
    "```\n",
    "START\n",
    "  |\n",
    "  v\n",
    "+-------+\n",
    "| NODE1 |  <=== checkpoint\n",
    "+-------+\n",
    "  |\n",
    "  v\n",
    "Superstep ①\n",
    "  |\n",
    "  v\n",
    "+-------+          +--------+\n",
    "| NODE2 | <------> | NODE1  |\n",
    "+-------+          +--------+\n",
    "  |                  ^\n",
    "  v                  |\n",
    "+--------+           |\n",
    "| NODE3  |-----------\n",
    "+--------+\n",
    "  |\n",
    "  v\n",
    "Superstep ②\n",
    "  |\n",
    "  v\n",
    "+--------+\n",
    "| NODE4  | <=== checkpoint\n",
    "+--------+\n",
    "  |\n",
    "  v\n",
    "Superstep ③\n",
    "  |\n",
    "  v\n",
    "+--------+\n",
    "|  I/O   |\n",
    "+--------+ <=== checkpoint\n",
    "\n",
    "Superstep ④\n",
    "\n",
    "  ↑\n",
    "  |\n",
    "+--------+\n",
    "| NODE1  |  <=== checkpoint\n",
    "+--------+\n",
    "\n",
    "Superstep ⑤\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a43d72a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from typing import TypedDict\n",
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv\n",
    "from langgraph.checkpoint.memory import InMemorySaver # this is kind of checkpointer that helps in implementation on checkpointers, this saves all the states in RAM this is mostly used in demo projects in production we use different checkpointers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe962a5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello. How can I assist you today?'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "load_dotenv()\n",
    "key = os.getenv(\"GROQ_API_KEY\")\n",
    "llm = ChatGroq(model=\"llama-3.3-70b-versatile\", api_key=key)\n",
    "llm.invoke(\"hello\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10e67e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#state\n",
    "\n",
    "class JokeState(TypedDict):\n",
    "    topic: str\n",
    "    joke: str\n",
    "    explanation : str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf5318e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_joke(state: JokeState):\n",
    "    prompt = f\"write an joke on topic - {state['topic']} in 20 words\"\n",
    "    joke = llm.invoke(prompt).content\n",
    "    return {\"joke\": joke}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71c99069",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_explanation(state: JokeState):\n",
    "    prompt = f\"write explanation for the joke - {state['joke']} in 30 words\"\n",
    "    explanation = llm.invoke(prompt).content\n",
    "    return {\"explanation\": explanation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01356ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(JokeState)\n",
    "\n",
    "graph.add_node(\"generate_joke\", generate_joke)\n",
    "graph.add_node(\"generate_explanation\", generate_explanation)\n",
    "\n",
    "graph.add_edge(START, \"generate_joke\")\n",
    "graph.add_edge(\"generate_joke\", 'generate_explanation')\n",
    "graph.add_edge('generate_explanation', END)\n",
    "\n",
    "# IN ORDER TO MAKE SURE OUR WORKFLOW IMPLEMENT IMPLEMENTS PERSISTENT\n",
    "#WE MAKE A CHECKPOINTER\n",
    "checkpointer = InMemorySaver()\n",
    "\n",
    "workflow = graph.compile(checkpointer=checkpointer) # send checkpointer while compiling the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "166cdbae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic': 'ai',\n",
       " 'joke': 'Why did AI go to therapy? It had a little \"glitch\" in its thought process always.',\n",
       " 'explanation': 'The joke plays on \"glitch\" meaning both a technical AI error and a mental issue, creating a humorous connection to therapy.'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config1 = {\"configurable\":{'thread_id': \"1\"}} # while executing persistence we send a thread id and against that thread id all the state will be stored \n",
    "\n",
    "workflow.invoke({\"topic\":\"ai\"}, config=config1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "265cb6ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'topic': 'ai', 'joke': 'Why did AI go to therapy? It had a little \"glitch\" in its thought process always.', 'explanation': 'The joke plays on \"glitch\" meaning both a technical AI error and a mental issue, creating a humorous connection to therapy.'}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f06f8ae-b43c-6cc8-8002-dee0f0d2eaee'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2025-08-02T10:24:49.174413+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f06f8ae-b20d-6bcb-8001-8c40dfcef62e'}}, tasks=(), interrupts=())"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# THIS WILL GIVE THIS FINAL STATE\n",
    "workflow.get_state(config1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2ec855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IF WE HAVE USED THE DATABASE MEMROY SAVER THEN AFTER MANY DAYS IF YOU RE RUN THE ABOVE CODE IT WILL GIVE THE ALLL THE SATE RESULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "311b61e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StateSnapshot(values={'topic': 'ai', 'joke': 'Why did AI go to therapy? It had a little \"glitch\" in its thought process always.', 'explanation': 'The joke plays on \"glitch\" meaning both a technical AI error and a mental issue, creating a humorous connection to therapy.'}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f06f8ae-b43c-6cc8-8002-dee0f0d2eaee'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2025-08-02T10:24:49.174413+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f06f8ae-b20d-6bcb-8001-8c40dfcef62e'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'ai', 'joke': 'Why did AI go to therapy? It had a little \"glitch\" in its thought process always.'}, next=('generate_explanation',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f06f8ae-b20d-6bcb-8001-8c40dfcef62e'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2025-08-02T10:24:48.945420+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f06f8ae-ad1c-65be-8000-375907bea4ff'}}, tasks=(PregelTask(id='963458a5-c28b-25f5-12cc-ef051bdec551', name='generate_explanation', path=('__pregel_pull', 'generate_explanation'), error=None, interrupts=(), state=None, result={'explanation': 'The joke plays on \"glitch\" meaning both a technical AI error and a mental issue, creating a humorous connection to therapy.'}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'ai'}, next=('generate_joke',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f06f8ae-ad1c-65be-8000-375907bea4ff'}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, created_at='2025-08-02T10:24:48.427118+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f06f8ae-ac9e-6ebe-bfff-82ba2889faee'}}, tasks=(PregelTask(id='2308946c-9453-ee5f-42f0-e505c8bf1566', name='generate_joke', path=('__pregel_pull', 'generate_joke'), error=None, interrupts=(), state=None, result={'joke': 'Why did AI go to therapy? It had a little \"glitch\" in its thought process always.'}),), interrupts=()),\n",
       " StateSnapshot(values={}, next=('__start__',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f06f8ae-ac9e-6ebe-bfff-82ba2889faee'}}, metadata={'source': 'input', 'step': -1, 'parents': {}}, created_at='2025-08-02T10:24:48.375691+00:00', parent_config=None, tasks=(PregelTask(id='c67a1f23-cff8-678d-7dc0-1601be14324a', name='__start__', path=('__pregel_pull', '__start__'), error=None, interrupts=(), state=None, result={'topic': 'ai'}),), interrupts=())]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO SEE INTERMEDIATE STATE VALUES\n",
    "list(workflow.get_state_history(config1)) # we see 4 values for all the checkpointer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4d70b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3c1ce145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StateSnapshot(values={'topic': 'ai', 'joke': 'Why did AI go to therapy? It had a little \"glitch\" to work out, logically speaking.', 'explanation': 'The joke plays on the word \"glitch,\" referencing both AI\\'s technical issues and emotional problems to be worked out in therapy, creating a humorous pun.'}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f06f74f-c61a-6022-8002-658551b354e1'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2025-08-02T07:47:48.963077+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f06f74f-c3d6-6d39-8001-724f7736a456'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'ai', 'joke': 'Why did AI go to therapy? It had a little \"glitch\" to work out, logically speaking.'}, next=('generate_explanation',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f06f74f-c3d6-6d39-8001-724f7736a456'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2025-08-02T07:47:48.725849+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f06f74f-c1c2-61cd-8000-1d943754c235'}}, tasks=(PregelTask(id='cb318e55-e64f-9a8f-fddf-db74c3f9f6fb', name='generate_explanation', path=('__pregel_pull', 'generate_explanation'), error=None, interrupts=(), state=None, result={'explanation': 'The joke plays on the word \"glitch,\" referencing both AI\\'s technical issues and emotional problems to be worked out in therapy, creating a humorous pun.'}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'ai'}, next=('generate_joke',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f06f74f-c1c2-61cd-8000-1d943754c235'}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, created_at='2025-08-02T07:47:48.507632+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f06f74f-c1b5-6077-bfff-eb0b0988d621'}}, tasks=(PregelTask(id='81cdfa40-f669-82e8-4b74-2397e0e6b83d', name='generate_joke', path=('__pregel_pull', 'generate_joke'), error=None, interrupts=(), state=None, result={'joke': 'Why did AI go to therapy? It had a little \"glitch\" to work out, logically speaking.'}),), interrupts=()),\n",
       " StateSnapshot(values={}, next=('__start__',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f06f74f-c1b5-6077-bfff-eb0b0988d621'}}, metadata={'source': 'input', 'step': -1, 'parents': {}}, created_at='2025-08-02T07:47:48.502307+00:00', parent_config=None, tasks=(PregelTask(id='efec489e-82a0-6608-93ee-822bf086d48b', name='__start__', path=('__pregel_pull', '__start__'), error=None, interrupts=(), state=None, result={'topic': 'ai'}),), interrupts=())]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config2 = {\"configurable\":{'thread_id': \"2\"}} \n",
    "\n",
    "workflow.invoke({\"topic\":\"ai\"}, config=config2)\n",
    "\n",
    "list(workflow.get_state_history(config1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbef865",
   "metadata": {},
   "source": [
    "### Benefits of Persistence in AI Systems\n",
    "\n",
    "- **🔹 1. Short-Term Memory** : Essential for chatbots to maintain conversation context.\n",
    "\n",
    "\n",
    "- **🔹 2. Fault Tolerance** : Allows resuming workflows from the last known state.      Stores intermediate data for recovery.\n",
    "\n",
    "\n",
    "- **🔹 3. Time Travel (Debugging)** : Enables replaying past states.         Helps trace and fix bugs efficiently.\n",
    "\n",
    "\n",
    "- **🔹 4. Human-in-the-Loop** : Maintains continuity during manual interventions.           Supports interactive AI workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061156bf",
   "metadata": {},
   "source": [
    "### 1. Fault Tolerance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5a10c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "# 1. Define the state\n",
    "class CrashState(TypedDict):\n",
    "    input: str\n",
    "    step1: str\n",
    "    step2: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44c4f981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Define steps\n",
    "def step_1(state: CrashState) -> CrashState:\n",
    "    print(\"✅ Step 1 executed\")\n",
    "    return {\"step1\": \"done\", \"input\": state[\"input\"]}\n",
    "\n",
    "def step_2(state: CrashState) -> CrashState:\n",
    "    print(\"⏳ Step 2 hanging... now manually interrupt from the notebook toolbar (STOP button)\")\n",
    "    time.sleep(1000)  # Simulate long-running hang\n",
    "    return {\"step2\": \"done\"}\n",
    "\n",
    "def step_3(state: CrashState) -> CrashState:\n",
    "    print(\"✅ Step 3 executed\")\n",
    "    return {\"done\": True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d47b4469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Build the graph\n",
    "builder = StateGraph(CrashState)\n",
    "builder.add_node(\"step_1\", step_1)\n",
    "builder.add_node(\"step_2\", step_2)\n",
    "builder.add_node(\"step_3\", step_3)\n",
    "\n",
    "builder.set_entry_point(\"step_1\")\n",
    "builder.add_edge(\"step_1\", \"step_2\")\n",
    "builder.add_edge(\"step_2\", \"step_3\")\n",
    "builder.add_edge(\"step_3\", END)\n",
    "\n",
    "checkpointer = InMemorySaver()\n",
    "graph = builder.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c695eb39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Running graph: Please manually interrupt during Step 2...\n",
      "✅ Step 1 executed\n",
      "⏳ Step 2 hanging... now manually interrupt from the notebook toolbar (STOP button)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(\"▶️ Running graph: Please manually interrupt during Step 2...\")\n",
    "    graph.invoke({\"input\": \"start\"}, config={\"configurable\": {\"thread_id\": 'thread-1'}})\n",
    "except KeyboardInterrupt:\n",
    "    print(\"❌ Kernel manually interrupted (crash simulated).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b007cab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔁 Re-running the graph to demonstrate fault tolerance...\n"
     ]
    },
    {
     "ename": "EmptyInputError",
     "evalue": "Received no input for __start__",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mEmptyInputError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 6. Re-run to show fault-tolerant resume\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m🔁 Re-running the graph to demonstrate fault tolerance...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m final_state = \u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mconfigurable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mthread_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mthread-1\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m✅ Final State:\u001b[39m\u001b[33m\"\u001b[39m, final_state)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\shubu\\Desktop\\Agentic AI\\my_env\\Lib\\site-packages\\langgraph\\pregel\\main.py:3019\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, **kwargs)\u001b[39m\n\u001b[32m   3016\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3017\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3019\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3020\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3021\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3022\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3023\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   3024\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   3025\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3026\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3027\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3028\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3029\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3030\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3031\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3032\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   3033\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\shubu\\Desktop\\Agentic AI\\my_env\\Lib\\site-packages\\langgraph\\pregel\\main.py:2586\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2583\u001b[39m runtime = parent_runtime.merge(runtime)\n\u001b[32m   2584\u001b[39m config[CONF][CONFIG_KEY_RUNTIME] = runtime\n\u001b[32m-> \u001b[39m\u001b[32m2586\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mSyncPregelLoop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2587\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2588\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStreamProtocol\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_modes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2589\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2590\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2591\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2592\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheckpointer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpointer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2593\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2594\u001b[39m \u001b[43m    \u001b[49m\u001b[43mspecs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2595\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2596\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minput_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2597\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream_channels_asis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2598\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2599\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2600\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2601\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2602\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrigger_to_nodes\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrigger_to_nodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2603\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmigrate_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_migrate_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2604\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2605\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcache_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2606\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2607\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# create runner\u001b[39;49;00m\n\u001b[32m   2608\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mPregelRunner\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2609\u001b[39m \u001b[43m        \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[43mCONF\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2610\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_RUNNER_SUBMIT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mWeakMethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2613\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnode_finished\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[43mCONF\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCONFIG_KEY_NODE_FINISHED\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2614\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2615\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# enable subgraph streaming\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\shubu\\Desktop\\Agentic AI\\my_env\\Lib\\site-packages\\langgraph\\pregel\\_loop.py:1039\u001b[39m, in \u001b[36mSyncPregelLoop.__enter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1037\u001b[39m \u001b[38;5;28mself\u001b[39m.stop = \u001b[38;5;28mself\u001b[39m.step + \u001b[38;5;28mself\u001b[39m.config[\u001b[33m\"\u001b[39m\u001b[33mrecursion_limit\u001b[39m\u001b[33m\"\u001b[39m] + \u001b[32m1\u001b[39m\n\u001b[32m   1038\u001b[39m \u001b[38;5;28mself\u001b[39m.checkpoint_previous_versions = \u001b[38;5;28mself\u001b[39m.checkpoint[\u001b[33m\"\u001b[39m\u001b[33mchannel_versions\u001b[39m\u001b[33m\"\u001b[39m].copy()\n\u001b[32m-> \u001b[39m\u001b[32m1039\u001b[39m \u001b[38;5;28mself\u001b[39m.updated_channels = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_first\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minput_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1041\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\shubu\\Desktop\\Agentic AI\\my_env\\Lib\\site-packages\\langgraph\\pregel\\_loop.py:666\u001b[39m, in \u001b[36mPregelLoop._first\u001b[39m\u001b[34m(self, input_keys)\u001b[39m\n\u001b[32m    664\u001b[39m     \u001b[38;5;28mself\u001b[39m._put_checkpoint({\u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33minput\u001b[39m\u001b[33m\"\u001b[39m})\n\u001b[32m    665\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m CONFIG_KEY_RESUMING \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m configurable:\n\u001b[32m--> \u001b[39m\u001b[32m666\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m EmptyInputError(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mReceived no input for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    667\u001b[39m \u001b[38;5;66;03m# update config\u001b[39;00m\n\u001b[32m    668\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_nested:\n",
      "\u001b[31mEmptyInputError\u001b[39m: Received no input for __start__"
     ]
    }
   ],
   "source": [
    "\n",
    "# 6. Re-run to show fault-tolerant resume\n",
    "print(\"\\n🔁 Re-running the graph to demonstrate fault tolerance...\")\n",
    "final_state = graph.invoke(None, config={\"configurable\": {\"thread_id\": 'thread-1'}}) # we give none to tell we wamt to resume where it previously stopped\n",
    "print(\"\\n✅ Final State:\", final_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6363c549",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "list(graph.get_state_history({\"configurable\": {\"thread_id\": 'thread-1'}}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6012806",
   "metadata": {},
   "source": [
    "### Time Travel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "caaefc58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'topic': 'ai', 'joke': 'Why did AI go to therapy? It had a little \"glitch\" in its thought process always.'}, next=('generate_explanation',), config={'configurable': {'thread_id': '1', 'checkpoint_id': '1f06f8ae-b20d-6bcb-8001-8c40dfcef62e'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2025-08-02T10:24:48.945420+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f06f8ae-ad1c-65be-8000-375907bea4ff'}}, tasks=(PregelTask(id='963458a5-c28b-25f5-12cc-ef051bdec551', name='generate_explanation', path=('__pregel_pull', 'generate_explanation'), error=None, interrupts=(), state=None, result={'explanation': 'The joke plays on \"glitch\" meaning both a technical AI error and a mental issue, creating a humorous connection to therapy.'}),), interrupts=())"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we will pass checkpoint id to get intermediate state\n",
    "workflow.get_state({\"configurable\": {\"thread_id\": \"1\", \"checkpoint_id\": \"1f06f8ae-b20d-6bcb-8001-8c40dfcef62e\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec8956e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic': 'ai',\n",
       " 'joke': 'Why did AI go to therapy? It had a little \"glitch\" in its thought process always.',\n",
       " 'explanation': 'The joke plays on \"glitch\" meaning both a technical AI error and a mental issue, requiring therapy to resolve its thought process problems.'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and to start execution from the intermediate state and input state is given as none\n",
    "workflow.invoke(None, {\"configurable\": {\"thread_id\": \"1\", \"checkpoint_id\": \"1f06f8ae-b20d-6bcb-8001-8c40dfcef62e\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "efc068e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StateSnapshot(values={'topic': 'ai', 'joke': 'Why did AI go to therapy? It had a little \"glitch\" in its thought process always.', 'explanation': 'The joke plays on \"glitch\" meaning both a technical AI error and a mental issue, requiring therapy to resolve its thought process problems.'}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f06f8b1-7121-6922-8002-78b374991a84'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2025-08-02T10:26:02.668424+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f06f8ae-b20d-6bcb-8001-8c40dfcef62e'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'ai', 'joke': 'Why did AI go to therapy? It had a little \"glitch\" in its thought process always.', 'explanation': 'The joke plays on \"glitch\" meaning both a technical AI error and a mental issue, creating a humorous connection to therapy.'}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f06f8ae-b43c-6cc8-8002-dee0f0d2eaee'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2025-08-02T10:24:49.174413+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f06f8ae-b20d-6bcb-8001-8c40dfcef62e'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'ai', 'joke': 'Why did AI go to therapy? It had a little \"glitch\" in its thought process always.'}, next=('generate_explanation',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f06f8ae-b20d-6bcb-8001-8c40dfcef62e'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2025-08-02T10:24:48.945420+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f06f8ae-ad1c-65be-8000-375907bea4ff'}}, tasks=(PregelTask(id='963458a5-c28b-25f5-12cc-ef051bdec551', name='generate_explanation', path=('__pregel_pull', 'generate_explanation'), error=None, interrupts=(), state=None, result={'explanation': 'The joke plays on \"glitch\" meaning both a technical AI error and a mental issue, creating a humorous connection to therapy.'}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'ai'}, next=('generate_joke',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f06f8ae-ad1c-65be-8000-375907bea4ff'}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, created_at='2025-08-02T10:24:48.427118+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f06f8ae-ac9e-6ebe-bfff-82ba2889faee'}}, tasks=(PregelTask(id='2308946c-9453-ee5f-42f0-e505c8bf1566', name='generate_joke', path=('__pregel_pull', 'generate_joke'), error=None, interrupts=(), state=None, result={'joke': 'Why did AI go to therapy? It had a little \"glitch\" in its thought process always.'}),), interrupts=()),\n",
       " StateSnapshot(values={}, next=('__start__',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f06f8ae-ac9e-6ebe-bfff-82ba2889faee'}}, metadata={'source': 'input', 'step': -1, 'parents': {}}, created_at='2025-08-02T10:24:48.375691+00:00', parent_config=None, tasks=(PregelTask(id='c67a1f23-cff8-678d-7dc0-1601be14324a', name='__start__', path=('__pregel_pull', '__start__'), error=None, interrupts=(), state=None, result={'topic': 'ai'}),), interrupts=())]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we will see more states as we did time travel\n",
    "list(workflow.get_state_history(config1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3f04eb",
   "metadata": {},
   "source": [
    "### Updating State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e6fcae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '1',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1f06f8bd-1120-6842-8000-76b96262123a'}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WE CAN CHANGE PARTICULATE STATE VALUE AT ANY CHECKPOINT (at last we changed the topic)\n",
    "\n",
    "workflow.update_state({\"configurable\": {\"thread_id\": \"1\", \"checkpoint_id\": \"1f06cc6e-7232-6cb1-8000-f71609e6cec5\", \"checkpoint_ns\": \"\"}}, {'topic':'samosa'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ced3e3d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StateSnapshot(values={'topic': 'samosa'}, next=('generate_joke',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f06f8bd-1120-6842-8000-76b96262123a'}}, metadata={'source': 'update', 'step': 0, 'parents': {}}, created_at='2025-08-02T10:31:14.724222+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f06cc6e-7232-6cb1-8000-f71609e6cec5'}}, tasks=(PregelTask(id='a3450019-6460-ec6d-16ed-71c35e4e2dd1', name='generate_joke', path=('__pregel_pull', 'generate_joke'), error=None, interrupts=(), state=None, result=None),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'ai', 'joke': 'Why did AI go to therapy? It had a little \"glitch\" in its thought process always.', 'explanation': 'The joke plays on \"glitch\" meaning both a technical AI error and a mental issue, requiring therapy to resolve its thought process problems.'}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f06f8b1-7121-6922-8002-78b374991a84'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2025-08-02T10:26:02.668424+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f06f8ae-b20d-6bcb-8001-8c40dfcef62e'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'ai', 'joke': 'Why did AI go to therapy? It had a little \"glitch\" in its thought process always.', 'explanation': 'The joke plays on \"glitch\" meaning both a technical AI error and a mental issue, creating a humorous connection to therapy.'}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f06f8ae-b43c-6cc8-8002-dee0f0d2eaee'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2025-08-02T10:24:49.174413+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f06f8ae-b20d-6bcb-8001-8c40dfcef62e'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'ai', 'joke': 'Why did AI go to therapy? It had a little \"glitch\" in its thought process always.'}, next=('generate_explanation',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f06f8ae-b20d-6bcb-8001-8c40dfcef62e'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2025-08-02T10:24:48.945420+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f06f8ae-ad1c-65be-8000-375907bea4ff'}}, tasks=(PregelTask(id='963458a5-c28b-25f5-12cc-ef051bdec551', name='generate_explanation', path=('__pregel_pull', 'generate_explanation'), error=None, interrupts=(), state=None, result={'explanation': 'The joke plays on \"glitch\" meaning both a technical AI error and a mental issue, creating a humorous connection to therapy.'}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'ai'}, next=('generate_joke',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f06f8ae-ad1c-65be-8000-375907bea4ff'}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, created_at='2025-08-02T10:24:48.427118+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f06f8ae-ac9e-6ebe-bfff-82ba2889faee'}}, tasks=(PregelTask(id='2308946c-9453-ee5f-42f0-e505c8bf1566', name='generate_joke', path=('__pregel_pull', 'generate_joke'), error=None, interrupts=(), state=None, result={'joke': 'Why did AI go to therapy? It had a little \"glitch\" in its thought process always.'}),), interrupts=()),\n",
       " StateSnapshot(values={}, next=('__start__',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f06f8ae-ac9e-6ebe-bfff-82ba2889faee'}}, metadata={'source': 'input', 'step': -1, 'parents': {}}, created_at='2025-08-02T10:24:48.375691+00:00', parent_config=None, tasks=(PregelTask(id='c67a1f23-cff8-678d-7dc0-1601be14324a', name='__start__', path=('__pregel_pull', '__start__'), error=None, interrupts=(), state=None, result={'topic': 'ai'}),), interrupts=())]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we will get additional state memory\n",
    "\n",
    "list(workflow.get_state_history(config1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f1cf41d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic': 'samosa',\n",
       " 'joke': 'Why was samosa in therapy? It was feeling a little \"crunchy\" under the pressure always.',\n",
       " 'explanation': 'The joke plays on \"crunchy\" referring to both the samosa\\'s texture and feeling overwhelmed under pressure, creating a humorous pun.'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Invoking for samosa\n",
    "workflow.invoke(None, {\"configurable\": {\"thread_id\": \"1\", \"checkpoint_id\": \"1f06f8bd-1120-6842-8000-76b96262123a\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fc84e621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StateSnapshot(values={'topic': 'samosa', 'joke': 'Why was samosa in therapy? It was feeling a little \"crunchy\" under the pressure always.', 'explanation': 'The joke plays on \"crunchy\" referring to both the samosa\\'s texture and feeling overwhelmed under pressure, creating a humorous pun.'}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f06f8c3-e050-6d55-8002-1f60498ebe79'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2025-08-02T10:34:17.510790+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f06f8c3-dde6-644d-8001-377253eb0cf5'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'samosa', 'joke': 'Why was samosa in therapy? It was feeling a little \"crunchy\" under the pressure always.'}, next=('generate_explanation',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f06f8c3-dde6-644d-8001-377253eb0cf5'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2025-08-02T10:34:17.257444+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f06f8bd-1120-6842-8000-76b96262123a'}}, tasks=(PregelTask(id='b0de611e-5389-2fe5-4cef-9513721196c6', name='generate_explanation', path=('__pregel_pull', 'generate_explanation'), error=None, interrupts=(), state=None, result={'explanation': 'The joke plays on \"crunchy\" referring to both the samosa\\'s texture and feeling overwhelmed under pressure, creating a humorous pun.'}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'samosa'}, next=('generate_joke',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f06f8bd-1120-6842-8000-76b96262123a'}}, metadata={'source': 'update', 'step': 0, 'parents': {}}, created_at='2025-08-02T10:31:14.724222+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f06cc6e-7232-6cb1-8000-f71609e6cec5'}}, tasks=(PregelTask(id='a3450019-6460-ec6d-16ed-71c35e4e2dd1', name='generate_joke', path=('__pregel_pull', 'generate_joke'), error=None, interrupts=(), state=None, result={'joke': 'Why was samosa in therapy? It was feeling a little \"crunchy\" under the pressure always.'}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'ai', 'joke': 'Why did AI go to therapy? It had a little \"glitch\" in its thought process always.', 'explanation': 'The joke plays on \"glitch\" meaning both a technical AI error and a mental issue, requiring therapy to resolve its thought process problems.'}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f06f8b1-7121-6922-8002-78b374991a84'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2025-08-02T10:26:02.668424+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f06f8ae-b20d-6bcb-8001-8c40dfcef62e'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'ai', 'joke': 'Why did AI go to therapy? It had a little \"glitch\" in its thought process always.', 'explanation': 'The joke plays on \"glitch\" meaning both a technical AI error and a mental issue, creating a humorous connection to therapy.'}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f06f8ae-b43c-6cc8-8002-dee0f0d2eaee'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2025-08-02T10:24:49.174413+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f06f8ae-b20d-6bcb-8001-8c40dfcef62e'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'ai', 'joke': 'Why did AI go to therapy? It had a little \"glitch\" in its thought process always.'}, next=('generate_explanation',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f06f8ae-b20d-6bcb-8001-8c40dfcef62e'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2025-08-02T10:24:48.945420+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f06f8ae-ad1c-65be-8000-375907bea4ff'}}, tasks=(PregelTask(id='963458a5-c28b-25f5-12cc-ef051bdec551', name='generate_explanation', path=('__pregel_pull', 'generate_explanation'), error=None, interrupts=(), state=None, result={'explanation': 'The joke plays on \"glitch\" meaning both a technical AI error and a mental issue, creating a humorous connection to therapy.'}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'ai'}, next=('generate_joke',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f06f8ae-ad1c-65be-8000-375907bea4ff'}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, created_at='2025-08-02T10:24:48.427118+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f06f8ae-ac9e-6ebe-bfff-82ba2889faee'}}, tasks=(PregelTask(id='2308946c-9453-ee5f-42f0-e505c8bf1566', name='generate_joke', path=('__pregel_pull', 'generate_joke'), error=None, interrupts=(), state=None, result={'joke': 'Why did AI go to therapy? It had a little \"glitch\" in its thought process always.'}),), interrupts=()),\n",
       " StateSnapshot(values={}, next=('__start__',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f06f8ae-ac9e-6ebe-bfff-82ba2889faee'}}, metadata={'source': 'input', 'step': -1, 'parents': {}}, created_at='2025-08-02T10:24:48.375691+00:00', parent_config=None, tasks=(PregelTask(id='c67a1f23-cff8-678d-7dc0-1601be14324a', name='__start__', path=('__pregel_pull', '__start__'), error=None, interrupts=(), state=None, result={'topic': 'ai'}),), interrupts=())]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "list(workflow.get_state_history(config1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
